{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5d472b84",
   "metadata": {},
   "source": [
    "#Ans1.)\n",
    "\n",
    "Describe the decision tree classifier algorithm and how it works to make predictions.\n",
    "\n",
    "Decision tree classifier is a popular supervised learning algorithm used for both classification and regression tasks.\n",
    "It works by recursively partitioning the feature space into regions, where each region corresponds to a specific class label (in classification).\n",
    "At each node of the tree, the algorithm selects the best feature to split the data based on certain criteria (e.g., Gini impurity, entropy).\n",
    "This process continues until the tree reaches a maximum depth, or no further splits provide significant improvement in class purity.\n",
    "To make predictions, the algorithm traverses down the tree based on the features of the input data until it reaches a leaf node, which corresponds to the predicted class label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f805ef35",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "586b4e96",
   "metadata": {},
   "source": [
    "#Ans2.)\n",
    "\n",
    "Decision tree classification involves selecting the best feature to split the data at each node in order to maximize the purity of the resulting child nodes.\n",
    "The purity of a node can be measured using metrics like Gini impurity or entropy. Gini impurity measures the probability of misclassifying a randomly chosen sample if it were labeled according to the distribution of classes in the node.\n",
    "The algorithm calculates the impurity of each possible split for each feature and selects the split that results in the lowest impurity.\n",
    "This process is repeated recursively for each child node until a stopping criterion is met, such as reaching a maximum tree depth or having nodes with no further improvement in impurity."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc8866dc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "36053022",
   "metadata": {},
   "source": [
    "#Ans3.)\n",
    "\n",
    "In a binary classification problem, a decision tree classifier splits the feature space into two regions, each corresponding to one of the two class labels.\n",
    "At each node, the algorithm selects the feature and the threshold value that best separates the data into the two classes.\n",
    "The process continues recursively until the tree reaches a maximum depth or a stopping criterion is met.\n",
    "To classify a new instance, the algorithm traverses down the tree based on the feature values of the instance until it reaches a leaf node, which corresponds to the predicted class label."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b22e9141",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "70226630",
   "metadata": {},
   "source": [
    "#Ans4.)\n",
    "\n",
    "Geometrically, decision tree classification can be visualized as partitioning the feature space into rectangular regions.\n",
    "Each split in the decision tree corresponds to a hyperplane that divides the feature space into two parts based on the value of a single feature.\n",
    "The decision boundaries formed by these splits are orthogonal to the feature axes.\n",
    "To make predictions, the algorithm assigns the majority class label of the training instances in each leaf node. When a new instance is presented, it follows the decision path down the tree until it reaches a leaf node, where the majority class label determines the prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a31c77e0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "f7f32cab",
   "metadata": {},
   "source": [
    "#Ans5.)\n",
    "\n",
    "A confusion matrix is a table that summarizes the performance of a classification model by comparing the actual class labels of the test data with the predicted class labels.\n",
    "It consists of four counts: true positives (TP), true negatives (TN), false positives (FP), and false negatives (FN).\n",
    "The confusion matrix provides insights into the model's accuracy, precision, recall, and F1 score, which are derived from these counts."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "399e8080",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "37e7a8e4",
   "metadata": {},
   "source": [
    "#Ans6.)\n",
    "\n",
    "              Predicted Negative   Predicted Positive\n",
    "Actual Negative         TN                  FP\n",
    "Actual Positive         FN                  TP\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "Precision = TP / (TP + FP)\n",
    "Recall = TP / (TP + FN)\n",
    "F1 score = 2 * (Precision * Recall) / (Precision + Recall)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "077f1a80",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "d925545a",
   "metadata": {},
   "source": [
    "#Ans.7)\n",
    "\n",
    "\n",
    "Choosing the right evaluation metric is crucial as it determines how the model's performance is assessed and compared.\n",
    "The choice of metric depends on the problem domain, class distribution, and the relative importance of false positives and false negatives.\n",
    "Common evaluation metrics for classification include accuracy, precision, recall, F1 score, ROC AUC, and others.\n",
    "Understanding the requirements and implications of each metric helps in selecting the most appropriate one for the specific problem at hand."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e460e4d8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "ce7b5a56",
   "metadata": {},
   "source": [
    "#Ans8.)\n",
    "\n",
    "In a medical diagnosis task where the positive class represents a severe disease (e.g., cancer), precision is crucial because false positives can lead to unnecessary treatments or anxiety for patients. It's important to minimize false positives to ensure that patients diagnosed as positive actually have the disease"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "245d8f1c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "dfc7d7d6",
   "metadata": {},
   "source": [
    "#Ans9.)\n",
    "\n",
    "In a fraud detection task, recall is more important than precision because missing actual fraud cases (false negatives) can have significant financial consequences. It's better to have some false positives (i.e., flagging non-fraudulent transactions as fraud) than to miss actual fraudulent transactions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40a59d3f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e4975c2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
